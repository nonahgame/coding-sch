{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nonahgame/coding-sch/blob/main/Copy_of_part1_text2num_CCbertChars_helper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n",
        "|-|:-:|\n",
        "|<h2>Part 1:</h2>|<h1>Tokenizations and embeddings<h1>|\n",
        "|<h2>Section:</h2>|<h1>Words to tokens to numbers<h1>|\n",
        "|<h2>Lecture:</h2>|<h1><b>CodeChallenge HELPER: Character counts in BERT tokens<b></h1>|\n",
        "\n",
        "<br>\n",
        "\n",
        "<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n",
        "<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n",
        "<i>Using the code without the course may lead to confusion or errors.</i>"
      ],
      "metadata": {
        "id": "n1LB6Jsc-8o-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fcZuEIvjV3dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTp8j3TJAqvB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import string\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib_inline.backend_inline\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load BERT tokenizer\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "STH_qxPP3BtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4uQ1UO6G-PAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1: Character counts in BERT tokens"
      ],
      "metadata": {
        "id": "MiXKcTVd-OfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set of digits and letters\n",
        "digitsLetters = digits + letters\n",
        "\n",
        "# initialize results vector\n",
        "charCount = np.zeros()\n",
        "\n",
        "# count the appearances (excluding \"unused\")\n",
        "for i,c in enumerate(digitsLetters):\n",
        "  charCount[i] = np.sum([ something in tokenizer.vocab.keys() if not something ])"
      ],
      "metadata": {
        "id": "-kqSP7GI3FDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set of digits and letters\n",
        "from string import digits, ascii_letters\n",
        "digitsLetters = digits + ascii_letters #letters\n",
        "\n",
        "# initialize results vector\n",
        "#charCount = np.zeros()\n",
        "charCount = np.zeros(len(digitsLetters), dtype=int)\n",
        "\n",
        "for i, c in enumerate(digitsLetters):\n",
        "  charCount[i] = np.sum(10 if c in tokenizer.vocab else 0)"
      ],
      "metadata": {
        "id": "MaJK9HcCO6zT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DE9je0iLO6lX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n63NoQ2B_GS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cdhBUOHf9nQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and plot not working\n",
        "plt.figure(figsize=(12,3))\n",
        "plt.bar(range(),color=[.7,.7,.7],edgecolor='k')\n",
        "\n",
        "plt.gca().set(xticks=range(len(charCount)),xticklabels=list(digitsLetters),\n",
        "              xlim=[-.6,len(charCount)-.4],xlabel='Character',ylabel='Count',\n",
        "              title='Frequency of characters in BERT tokens')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H7byXz2-3FAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import matplotlib.pyplot as plt\n",
        "#import numpy as np\n",
        "#from string import digits, ascii_letters\n",
        "\n",
        "# (Assuming you already have tokenizer and charCount filled in previous cells)\n",
        "\n",
        "digitsLetters = digits + ascii_letters\n",
        "\n",
        "# If you still need to compute charCount (just in case):\n",
        "# charCount = np.array([1 if c in tokenizer.vocab else 0 for c in digitsLetters], dtype=int)\n",
        "\n",
        "# ── Plot ───────────────────────────────────────────────────────────────\n",
        "plt.figure(figsize=(14, 4))   # wider is better for 62 characters\n",
        "\n",
        "plt.bar(\n",
        "    x=range(len(charCount)),          # 0, 1, 2, ..., 61\n",
        "    height=charCount,                 # ← this was missing!\n",
        "    color='lightgray',\n",
        "    edgecolor='black',\n",
        "    linewidth=0.8\n",
        ")\n",
        "\n",
        "plt.xticks(\n",
        "    ticks=range(len(charCount)),\n",
        "    labels=list(digitsLetters),\n",
        "    fontsize=9.5,\n",
        "    rotation=0\n",
        ")\n",
        "\n",
        "plt.xlim(-0.8, len(charCount) - 0.2)\n",
        "plt.xlabel('Character')\n",
        "plt.ylabel('Count (1 = present, 0 = missing)')\n",
        "plt.title('Presence of single characters in tokenizer vocabulary')\n",
        "\n",
        "plt.grid(axis='y', alpha=0.3, linestyle=':')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B_nfU71u-Tv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2: Report the sorted characters"
      ],
      "metadata": {
        "id": "7kP1eYYS-Ttb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# not working\n",
        "charOrder = np.argsort(-charCount)\n",
        "\n",
        "for i in charOrder:\n",
        "  print(f'\"{}\" appears in {} tokens.')"
      ],
      "metadata": {
        "id": "CH_A-Ya13E9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort characters by count (descending)\n",
        "order = np.argsort(-charCount)\n",
        "\n",
        "print(\"Single characters found in tokenizer vocab (most to least common):\")\n",
        "for i in order:\n",
        "    if charCount[i] > 0:\n",
        "        print(f'\"{digitsLetters[i]}\"')"
      ],
      "metadata": {
        "id": "x7O90GnPOciC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for char, cnt in sorted(zip(digitsLetters, charCount), key=lambda x: -x[1]):\n",
        "    if cnt > 0:\n",
        "        print(f'\"{char}\" → present')\n",
        "    # or:\n",
        "    # print(f'\"{char}\" → {cnt}')"
      ],
      "metadata": {
        "id": "jNxC2r28_MVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_chars = [digitsLetters[i] for i in np.argsort(-charCount) if charCount[i] > 0]\n",
        "\n",
        "print(\"Characters present in the vocabulary:\")\n",
        "for rank, char in enumerate(sorted_chars, 1):\n",
        "    print(f\"{rank:2d}. {char}\")"
      ],
      "metadata": {
        "id": "xSKoXxCiPtVx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}